{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime, json, os, re, zstandard\n",
    "from nltk.corpus import stopwords\n",
    "from zst_processor import read_lines_zst, write_line_zst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = [\"Conservative\", \"progressive\",\n",
    "              \"democrats\", \"Republican\",\n",
    "              \"NeutralPolitics\", \"PoliticalDiscussion\", \"politics\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find main topics being discussed in the subreddits.\n",
    "\n",
    "Apply topic modeling techniques such as Latent Dirichlet Allocation (LDA) or Non-negative Matrix Factorization (NMF) to extract the main topics discussed within each subreddit. This will help you identify the prevalent themes and subjects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_submissions = [f\"data/{s}/{s}_submissions_clean.zst\" for s in subreddits]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Latent Dirichlet Allocation (LDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.utils import tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_submission(text: str, stop_words: list) -> str:\n",
    "    \"\"\"Clean text by removing non-alphabetical characters, stop words,\n",
    "    and other words\"\"\"\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove stop words\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "    # Remove 's \n",
    "    text = text.replace(\"'s \", ' ')\n",
    "\n",
    "    # Remove non-alphabetical characters\n",
    "    text = re.sub(r'[^a-z ]+', '', text)\n",
    "\n",
    "\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find topics across multiple texts using LDA model\n",
    "def create_corpus(input_paths: list) -> None:\n",
    "    \"\"\"Find topics across multiple texts using LDA model\"\"\"\n",
    "\n",
    "    # Create empty list to store texts\n",
    "    texts = []\n",
    "\n",
    "    # Load stop words using nltk\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    # Custom stop words\n",
    "    custom_stop_words = ['biden', 'trump', 'republican', 'democrat', 'politics']\n",
    "    stop_words.extend(custom_stop_words)\n",
    "\n",
    "    # Loop through input paths\n",
    "    for path in input_paths:\n",
    "\n",
    "        # Read lines\n",
    "        lines = read_lines_zst(path)\n",
    "\n",
    "        # Loop through lines\n",
    "        for line, _ in lines:\n",
    "\n",
    "            # Convert the line to a json object\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            # Get text and title\n",
    "            text = obj['selftext']\n",
    "            title = obj['title']\n",
    "\n",
    "            # Skip if text is deleted, or removed\n",
    "            if (text == 'deleted') or (text == 'removed'):\n",
    "                continue\n",
    "\n",
    "            # Combine title and text\n",
    "            full_text = title + ' ' + text\n",
    "\n",
    "            # Clean text\n",
    "            full_text = clean_submission(full_text, stop_words)\n",
    "\n",
    "            # Skip if text is empty\n",
    "            if len(full_text) == 0:\n",
    "                continue\n",
    "\n",
    "            # Add to list\n",
    "            texts.append(full_text)\n",
    "\n",
    "    # Tokenize texts\n",
    "    tokenized_texts = [list(tokenize(text, lowercase=True)) for text in texts]\n",
    " \n",
    "    # Create dictionary\n",
    "    dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "    # Filter extremes (remove words that appear in more than 30% of documents and less than 10 documents)\n",
    "    dictionary.filter_extremes(no_below=10, no_above=0.3)\n",
    "\n",
    "    # Create corpus\n",
    "    corpus = [dictionary.doc2bow(tokens) for tokens in tokenized_texts]\n",
    "\n",
    "    return corpus, dictionary, tokenized_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corpus\n",
    "corpus, dictionary, tokenized_texts = create_corpus(input_submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the optimal number of topics using coherence scores\n",
    "def find_optimal_num_topics(corpus: list, dictionary: Dictionary, texts: list, limit: int, start: int=2, step: int=3) -> None:\n",
    "    \"\"\"Find the optimal number of topics\"\"\"\n",
    "\n",
    "    # Create empty list to store models\n",
    "    models = []\n",
    "\n",
    "    # Create empty list to store coherence scores\n",
    "    coherence_scores = []\n",
    "\n",
    "    # Loop through number of topics\n",
    "    for num_topics in range(start, limit, step):\n",
    "\n",
    "        # Create model\n",
    "        model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
    "\n",
    "        # Save model\n",
    "        models.append(model)\n",
    "\n",
    "        # Create coherence model\n",
    "        coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "\n",
    "        # Save coherence score\n",
    "        coherence_scores.append(coherence_model.get_coherence())\n",
    "\n",
    "    # Create dataframe of coherence scores\n",
    "    df = pd.DataFrame({'num_topics': range(start, limit, step), 'coherence_score': coherence_scores})\n",
    "\n",
    "    return models, coherence_scores, df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of topics\n",
    "lda_models, lda_coherence_scores, lda_df = find_optimal_num_topics(corpus, dictionary, tokenized_texts, limit=10, start=4, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "lda_df.to_csv('analysis/topic_modeling/lda_coherence_scores.csv', index=False)\n",
    "\n",
    "# Save models\n",
    "for i, model in enumerate(lda_models):\n",
    "    model.save(f'analysis/topic_modeling/lda_model_{i+3}.model')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>coherence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.566669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.589104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.558101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.500125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.526317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.523894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.495700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_topics  coherence_score\n",
       "0           3         0.566669\n",
       "1           4         0.589104\n",
       "2           5         0.558101\n",
       "3           6         0.500125\n",
       "4           7         0.526317\n",
       "5           8         0.523894\n",
       "6           9         0.495700"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hierarchical Dirichlet Process (HDP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import HdpModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run HDP model\n",
    "hdp_model = HdpModel(corpus=corpus, id2word=dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: us, would, president, people, house, election, like, state, one, states\n",
      "Topic: 1 \n",
      "Words: thread, happened, state, news, week, like, local, people, political, think\n",
      "Topic: 2 \n",
      "Words: cartoons, political, cartoon, toplevel, thread, means, comment, must, share, saturday\n",
      "Topic: 3 \n",
      "Words: im, like, people, dont, one, white, us, know, get, would\n",
      "Topic: 4 \n",
      "Words: epstein, ms, page, defendant, girls, jeffrey, sex, epsteins, sexual, testified\n",
      "Topic: 5 \n",
      "Words: people, dont, us, im, week, like, know, time, right, liberals\n",
      "Topic: 6 \n",
      "Words: cnn, us, government, would, caught, gt, cnns, claims, hillary, people\n",
      "Topic: 7 \n",
      "Words: sen, former, cnn, pm, rep, night, mayor, gov, apps, new\n",
      "Topic: 8 \n",
      "Words: security, negligence, attorney, general, resignation, deputy, care, us, people, letter\n",
      "Topic: 9 \n",
      "Words: gun, year, deaths, people, die, per, number, estimates, population, million\n",
      "Topic: 10 \n",
      "Words: us, one, left, im, think, people, american, ive, economy, time\n",
      "Topic: 11 \n",
      "Words: party, people, government, states, labor, like, federal, republicans, gt, rights\n",
      "Topic: 12 \n",
      "Words: people, college, loans, government, degree, pay, arts, dont, degrees, im\n",
      "Topic: 13 \n",
      "Words: sidebar, time, suggestions, ampxb, multiple, holocaust, like, tribute, community, camps\n",
      "Topic: 14 \n",
      "Words: house, session, democrats, override, wednesday, veto, members, republicans, votes, floor\n",
      "Topic: 15 \n",
      "Words: people, talk, years, lets, indirectly, better, like, dont, look, im\n",
      "Topic: 16 \n",
      "Words: states, united, people, better, way, usa, education, europe, healthcare, think\n",
      "Topic: 17 \n",
      "Words: blacks, democrats, republicans, party, democratic, nixon, passed, racist, vote, percent\n",
      "Topic: 18 \n",
      "Words: like, people, eu, years, dont, get, americans, us, im, theres\n",
      "Topic: 19 \n",
      "Words: conservative, like, get, would, think, one, conservatives, im, liberal, still\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in hdp_model.show_topics(formatted=False, num_words=10):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, ', '.join([w[0] for w in topic])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classify submissions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select lda model with highest coherence score\n",
    "optimal_lda_model = LdaModel.load('analysis/topic_modeling/lda_model_7.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: house, court, supreme, white, news, committee, judge, state, georgia, senate\n",
      "Topic: 1 \n",
      "Words: jan, says, s, us, desantis, election, maralago, donald, fbi, joe\n",
      "Topic: 2 \n",
      "Words: us, ukraine, covid, arizona, war, says, health, years, china, care\n",
      "Topic: 3 \n",
      "Words: new, bill, s, texas, states, law, tax, governor, plan, state\n",
      "Topic: 4 \n",
      "Words: s, senate, vote, capitol, gop, says, race, doj, us, general\n",
      "Topic: 5 \n",
      "Words: s, abortion, election, gop, voting, voters, poll, climate, party, ic\n",
      "Topic: 6 \n",
      "Words: people, one, dont, opinion, time, like, student, right, get, president\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in optimal_lda_model.show_topics(formatted=False, num_words=10):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, ', '.join([w[0] for w in topic])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function to classify submissions using lda model\n",
    "def classify_submissions(input_paths: list,\n",
    "                         output_paths: list,\n",
    "                         lda_model: LdaModel,\n",
    "                         dictionary: Dictionary) -> None:\n",
    "    \"\"\"Classify submissions using lda model\"\"\"\n",
    "\n",
    "    # Loop through input paths\n",
    "    for in_path, out_path in zip(input_paths, output_paths):\n",
    "\n",
    "        # Create the zst handler\n",
    "        handle = zstandard.ZstdCompressor().stream_writer(open(out_path, 'wb'))\n",
    "\n",
    "        # Save the data to zst file\n",
    "        with open(out_path, mode=\"w\", newline=\"\") as file:\n",
    "\n",
    "            for line, file_bytes_processed in read_lines_zst(in_path):\n",
    "                obj = json.loads(line)\n",
    "\n",
    "                # Get text and title\n",
    "                text = obj['selftext']\n",
    "                title = obj['title']\n",
    "\n",
    "                # Skip if text is deleted, or removed\n",
    "                if (text == 'deleted') or (text == 'removed'):\n",
    "                    continue\n",
    "\n",
    "                # Combine title and text\n",
    "                full_text = title + ' ' + text\n",
    "\n",
    "                # Skip if text is empty\n",
    "                if len(full_text) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Get topic distribution\n",
    "                topic_dist = lda_model.get_document_topics(dictionary.doc2bow(full_text.split()), minimum_probability=0.0)\n",
    "\n",
    "                # Add topic distribution to object (make it serializable)\n",
    "                obj['topic_dist'] = str(topic_dist)\n",
    "                \n",
    "                # Write the data to the zst file\n",
    "                new_line = json.dumps(obj)\n",
    "                write_line_zst(handle, new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submissions = [f\"data/topic_modeling/{s}_submissions_classified.zst\" for s in subreddits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify submissions\n",
    "classify_submissions(input_submissions, output_submissions, optimal_lda_model, dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
