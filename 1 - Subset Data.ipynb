{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset Data\n",
    "\n",
    "Select data from 2019 through 2022 for the appriopriate subreddits. Remove unnecessary columns and save the data to a zst file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import json, os, zstandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = [\"Conservative\", \"progressive\",\n",
    "                \"democrats\", \"Republican\",\n",
    "                \"NeutralPolitics\", \"PoliticalDiscussion\", \"politics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the start and end dates to subset the data\n",
    "start_date = datetime(2019, 1, 1)\n",
    "end_date = datetime(2022, 12, 31)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_submissions(input_path: str,\n",
    "                       output_path: str,\n",
    "                       start_date: datetime=None,\n",
    "                       end_date: datetime=None,\n",
    "                       keys: list=None):\n",
    "\n",
    "    # Create the zst handler\n",
    "    handle = zstandard.ZstdCompressor().stream_writer(open(output_path, 'wb'))\n",
    "\n",
    "    # Save the data to zst file\n",
    "    with open(output_path, mode=\"w\", newline=\"\") as file:\n",
    "\n",
    "        for line, file_bytes_processed in read_lines_zst(input_path):\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            # Filter out comments that don't have a created_utc field\n",
    "            if \"created_utc\" not in obj: continue\n",
    "            created_utc = datetime.fromtimestamp(int(obj[\"created_utc\"]))\n",
    "            \n",
    "            # Filter by date\n",
    "            if created_utc < start_date: continue\n",
    "            if created_utc > end_date: continue\n",
    "            \n",
    "            # Select the keys (if they exist)\n",
    "            obj = {key: obj.get(key, \"\") for key in keys}\n",
    "            \n",
    "            # Skip if selftext is empty or deleted\n",
    "            if obj[\"selftext\"] == \"\" or obj[\"selftext\"] == \"[deleted]\": continue\n",
    "\n",
    "            # if id is in the keys, change it to link_id\n",
    "            if \"id\" in keys:\n",
    "                # Select characters after underscore\n",
    "                try:\n",
    "                    obj[\"link_id\"] = obj[\"id\"].split(\"_\")[-1]\n",
    "                except:\n",
    "                    obj[\"link_id\"] = \"\"\n",
    "\n",
    "            # Write the data to the zst file\n",
    "            line_clean = json.dumps(obj)\n",
    "            write_line_zst(handle, line_clean)\n",
    "    \n",
    "    print(f\"Data written to {output_path}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the keys to keep\n",
    "keys_submissions = [\"id\", \"author\", \"downs\", \"ups\", \"title\", \"num_comments\", \"created_utc\", \"selftext\", \"score\"]\n",
    "\n",
    "for subreddit in subreddits:\n",
    "\n",
    "    # Set the input and output paths\n",
    "    input_path = f\"data/{subreddit}/{subreddit}_submissions.zst\"\n",
    "    output_path = f\"data/{subreddit}/{subreddit}_submissions_subset.zst\"\n",
    "\n",
    "    # Subset the data\n",
    "    subset_submissions(input_path, output_path, start_date, end_date, keys_submissions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_comments(input_path: str,\n",
    "                    output_path: str,\n",
    "                    start_date: datetime=None,\n",
    "                    end_date: datetime=None,\n",
    "                    keys: list=None):\n",
    "\n",
    "    # Create the zst handler\n",
    "    handle = zstandard.ZstdCompressor().stream_writer(open(output_path, 'wb'))\n",
    "\n",
    "    # Save the data to zst file\n",
    "    with open(output_path, mode=\"w\", newline=\"\") as file:\n",
    "\n",
    "        for line, file_bytes_processed in read_lines_zst(input_path):\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            # Filter out comments that don't have a created_utc field\n",
    "            if \"created_utc\" not in obj: continue\n",
    "            created_utc = datetime.fromtimestamp(int(obj[\"created_utc\"]))\n",
    "            \n",
    "            # Filter by date\n",
    "            if created_utc < start_date: continue\n",
    "            if created_utc > end_date: continue\n",
    "            \n",
    "            # Select the keys (if they exist)\n",
    "            obj = {key: obj.get(key, \"\") for key in keys}\n",
    "            \n",
    "            # Skip if body is empty or deleted\n",
    "            if obj[\"body\"] == \"\" or obj[\"body\"] == \"[deleted]\": continue\n",
    "\n",
    "            # Write the data to the zst file\n",
    "            line_clean = json.dumps(obj)\n",
    "            write_line_zst(handle, line_clean)\n",
    "    \n",
    "    print(f\"Data written to {output_path}\")\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the keys to keep\n",
    "keys_comments = [\"link_id\", \"author\", \"created_utc\", \"body\", \"score\", \"ups\", \"downs\", \"controversiality\", \"gilded\"]\n",
    "\n",
    "for subreddit in subreddits:\n",
    "\n",
    "    # Set the input and output paths\n",
    "    input_path = f\"data/{subreddit}/{subreddit}_comments.zst\"\n",
    "    output_path = f\"data/{subreddit}/{subreddit}_comments_subset.zst\"\n",
    "\n",
    "    # Subset the data\n",
    "    subset_comments(input_path, output_path, start_date, end_date, keys_comments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
