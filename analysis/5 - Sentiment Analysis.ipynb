{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ast, datetime, json, os, re, zstandard\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from zst_processor import read_lines_zst, write_line_zst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = [\"Conservative\", \"progressive\",\n",
    "              \"democrats\", \"Republican\",\n",
    "              \"NeutralPolitics\", \"PoliticalDiscussion\", \"politics\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotions using NRC Lexicon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up NRC Emotion Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NRC emotion lexicon from NRC-Emotion.txt\n",
    "nrc = {}\n",
    "with open('NRC-Emotion.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        words, emotion, value = line.strip().split('\\t')\n",
    "\n",
    "        # Replace - with spaces\n",
    "        words = words.replace('-', ' ').replace(\",\", ' ').replace(\"  \", \" \")\n",
    "\n",
    "        # Break words into a list of words\n",
    "        words = words.split(' ')\n",
    "\n",
    "        for word in words:\n",
    "            if word not in nrc.keys():\n",
    "                nrc[word] = {}\n",
    "            nrc[word][emotion] = int(value)\n",
    "\n",
    "# Save nrc to a json file as lexicon_clean.json\n",
    "with open('lexicon_clean.json', 'w') as f:\n",
    "    json.dump(nrc, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate comments emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add the sentiment of the comments in a submission\n",
    "def add_sentiment_comments(input_comments: list, output_comments: list, lexicon: dict) ->  None:\n",
    "    \"\"\"Add the sentiment of the comments in a submission\"\"\"\n",
    "\n",
    "    # Loop through input paths\n",
    "    for in_comment, out_comment in zip(input_comments, output_comments):\n",
    "\n",
    "        # Create the zst handler\n",
    "        handle = zstandard.ZstdCompressor().stream_writer(open(out_comment, 'wb'))\n",
    "\n",
    "        # Save the data to zst file\n",
    "        with open(out_comment, mode=\"w\", newline=\"\") as file:\n",
    "\n",
    "            for line, file_bytes_processed in read_lines_zst(in_comment):\n",
    "                obj = json.loads(line)\n",
    "\n",
    "                # Skip if body doesn't exist\n",
    "                if 'body' not in obj:\n",
    "                    continue\n",
    "\n",
    "                # Get body of comment\n",
    "                body = obj['body']\n",
    "\n",
    "                # Skip if body is deleted or removed\n",
    "                if (body == 'deleted') or (body == 'removed'):\n",
    "                    continue\n",
    "\n",
    "                # Skip if score or ups+downs is too low\n",
    "                if 'score' in obj:\n",
    "                    try: score = int(obj['score'])\n",
    "                    except: score = 0\n",
    "                    if score <= 5: continue\n",
    "                else:\n",
    "                    ups = obj.get('ups',0)\n",
    "                    try: ups = int(ups)\n",
    "                    except: ups = 0\n",
    "                    downs = obj.get('downs',0)\n",
    "                    try: downs = int(downs)\n",
    "                    except: downs = 0\n",
    "                    if (ups-downs) <= 5: continue\n",
    "\n",
    "                # Get polarity and subjectivity of body\n",
    "                polarity = TextBlob(body).sentiment.polarity\n",
    "                subjectivity = TextBlob(body).sentiment.subjectivity\n",
    "\n",
    "                # Calculate emotions in the comment using NRC emotion lexicon\n",
    "                emotions = {'fear': 0, 'anger': 0, 'anticip': 0, 'trust': 0,\n",
    "                            'surprise': 0, 'sadness': 0, 'joy': 0, 'disgust': 0,\n",
    "                            'positive': 0, 'negative': 0}\n",
    "                for word in body.split():\n",
    "                    if word in nrc_lexicon.keys():\n",
    "                        for emotion in nrc_lexicon[word].keys():\n",
    "                            emotions[emotion] = emotions.get(emotion, 0) + nrc_lexicon[word][emotion]\n",
    "\n",
    "                # Add sentiment and emotion to object\n",
    "                obj['polarity'] = polarity\n",
    "                obj['subjectivity'] = subjectivity\n",
    "                obj['emotions'] = emotions\n",
    "\n",
    "                # Remove body\n",
    "                del obj['body']\n",
    "\n",
    "                # Write the data to the zst file\n",
    "                new_line = json.dumps(obj)\n",
    "\n",
    "                write_line_zst(handle, new_line)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nrc_lexicon\n",
    "nrc_lexicon = json.load(open('lexicon_clean.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input and output paths\n",
    "input_comments = [f\"data/{s}/{s}_comments_clean.zst\" for s in subreddits]\n",
    "output_comments = [f\"data/sentiment/{s}_comments_sentiment.zst\" for s in subreddits]\n",
    "\n",
    "# Add sentiment to comments\n",
    "add_sentiment_comments(input_comments, output_comments, nrc_lexicon)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Submissions Polarity\n",
    "\n",
    "Assess the homogeneity of the discussions within each subreddit.\n",
    "\n",
    "* Measure the sentiment (positive, negative, or neutral) of (most engaged) comments on a specific post in each subreddit.\n",
    "Then, aggregate those sentiments, using upvotes and downvotes as weights, to get a sentiment score for each post. Finally, aggregate the sentiment scores of all posts in a subreddit to get a sentiment score for each subreddit on a specific topic.\n",
    "(consider using sentiment entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average sentiment towards each submission \n",
    "def calculate_sentiment_submission(input_comments: list, output_comments: list) -> None:\n",
    "    \"\"\"Calculate average sentiment towards each submission\"\"\"\n",
    "\n",
    "    # Loop through input paths\n",
    "    for in_comment, out_comment in zip(input_comments, output_comments):\n",
    "\n",
    "        # Create the zst handler\n",
    "        handle = zstandard.ZstdCompressor().stream_writer(open(out_comment, 'wb'))\n",
    "\n",
    "        # Save the data to zst file\n",
    "        with open(out_comment, mode=\"w\", newline=\"\") as file:\n",
    "\n",
    "            submissions = {}\n",
    "\n",
    "            for line, file_bytes_processed in read_lines_zst(in_comment):\n",
    "                obj = json.loads(line)\n",
    "\n",
    "                # Skip if body doesn't exist\n",
    "                if 'sentiment' not in obj or 'link_id' not in obj:\n",
    "                    continue\n",
    "\n",
    "                # Calculate score if ups and downs exist\n",
    "                if obj.get('ups', '0') != '0' or obj.get('downs', '0') != '0':\n",
    "\n",
    "                    # Give it a higher weight the more votes it has\n",
    "                    votes = obj['ups'] + obj['downs']\n",
    "                    if votes == 0: interactions = 1\n",
    "                    sentiment = obj['sentiment'] * votes\n",
    "                    interactions = obj['ups'] + abs(obj['downs'])\n",
    "                    \n",
    "                # Otherwise, use the score\n",
    "                else:\n",
    "                    interactions = max(obj['score'], 1)\n",
    "                    sentiment = obj['sentiment'] * interactions\n",
    "                \n",
    "                # Add sentiment to object\n",
    "                if obj['link_id'] not in submissions:\n",
    "                    submissions[obj['link_id']] = [sentiment, interactions]\n",
    "                else:\n",
    "                    submissions[obj['link_id']][0] += sentiment\n",
    "                    submissions[obj['link_id']][1] += interactions\n",
    "\n",
    "            # Save the data to zst file\n",
    "            for link_id, (sentiment, interactions) in submissions.items():\n",
    "                obj = {'link_id': link_id,\n",
    "                       'sentiment': sentiment,\n",
    "                       'interactions': interactions}\n",
    "                new_line = json.dumps(obj)\n",
    "                write_line_zst(handle, new_line)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input and output paths\n",
    "output_overall_sentiment = [f\"analysis/sentiment/{s}_submissions_overall_sentiment.zst\" for s in subreddits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_sentiment_submission(output_comments, output_overall_sentiment)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Comments Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_comments_sentiment = [f\"data/{s}/{s}_comments_sentiment.zst\" for s in subreddits if s != 'politics']\n",
    "output_submission_sentiment = [f\"analysis/sentiment/{s}_submissions_sentiment.zst\" for s in subreddits if s != 'politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate average emotion towards each submission\n",
    "def calculate_emotion_submission(input_comments_sentiment: list, output_submission_sentiment: list) -> None:\n",
    "    \n",
    "    emotions = {'fear': 0, 'anger': 0, 'anticip': 0, 'trust': 0,\n",
    "            'surprise': 0, 'sadness': 0, 'joy': 0, 'disgust': 0,\n",
    "            'positive': 0, 'negative': 0}\n",
    "\n",
    "    submissions = {}\n",
    "\n",
    "    # Loop through input paths\n",
    "    for in_comment, out_submission in zip(input_comments_sentiment, output_submission_sentiment):\n",
    "\n",
    "        # Create the zst handler\n",
    "        handle = zstandard.ZstdCompressor().stream_writer(open(out_submission, 'wb'))\n",
    "\n",
    "        # Save the data to zst file\n",
    "        with open(out_submission, mode=\"w\", newline=\"\") as file:\n",
    "\n",
    "            for line, file_bytes_processed in read_lines_zst(in_comment):\n",
    "                obj = json.loads(line)\n",
    "\n",
    "                # Skip if body doesn't exist\n",
    "                if 'link_id' not in obj:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate score if ups and downs exist\n",
    "                if obj.get('ups', '') == '': ups = 0\n",
    "                else: ups = int(obj.get('ups', ''))\n",
    "                if obj.get('downs', '') == '': downs = 0\n",
    "                else: downs = int(obj.get('downs', ''))\n",
    "\n",
    "                if ups != 0 or downs != 0:\n",
    "                    \n",
    "                    interactions = ups + downs\n",
    "                    if interactions == 0: interactions = 1\n",
    "                    \n",
    "                # Otherwise, use the score\n",
    "                else:\n",
    "                    interactions = max(obj['score'], 1)\n",
    "                \n",
    "                # Add polarity, subjectivity, and emotions to object\n",
    "                if obj['link_id'] not in submissions:\n",
    "                    submissions[obj['link_id']] = {'polarity': 0,\n",
    "                                                   'subjectivity': 0,\n",
    "                                                   'emotions': emotions.copy(),\n",
    "                                                   'interactions': 0}\n",
    "                \n",
    "                # Calculate average polarity, subjectivity, and emotions\n",
    "                submissions[obj['link_id']]['polarity'] += obj['polaritiy'] * interactions\n",
    "                submissions[obj['link_id']]['subjectivity'] += obj['subjectivity'] * interactions\n",
    "\n",
    "                for e in emotions:\n",
    "                    submissions[obj['link_id']]['emotions'][e] += obj['emotions'][e] * interactions\n",
    "                \n",
    "                # Add interactions\n",
    "                submissions[obj['link_id']]['interactions'] += interactions\n",
    "\n",
    "        # Save the data to zst file, including link_id\n",
    "        for link_id, obj in submissions.items():\n",
    "            obj['link_id'] = link_id\n",
    "            new_line = json.dumps(obj)\n",
    "            write_line_zst(handle, new_line)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_emotion_submission(input_comments_sentiment, output_submission_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_submissions_classified = [f\"data/sentiment/{s}_submissions_classified.zst\" for s in subreddits if s != 'politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For list of tuples, find tuple with highest value in second element and return first element\n",
    "def find_max_tuple(tuples: list) -> tuple:\n",
    "    \"\"\"Find tuple with highest value in second element\"\"\"\n",
    "\n",
    "    # Initialize max tuple\n",
    "    max_tuple = ('', 0)\n",
    "\n",
    "    # Loop through tuples\n",
    "    for t in tuples:\n",
    "\n",
    "        # Update max tuple if second element is greater than current max\n",
    "        if t[1] > max_tuple[1]:\n",
    "            max_tuple = t\n",
    "\n",
    "    return max_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submissions classified and get topic with highest probability\n",
    "submissions_classified = {s: {} for s in subreddits if s != 'politics'}\n",
    "\n",
    "for sub in subreddits[:-1]:\n",
    "\n",
    "    s_class = f\"data/sentiment/{sub}_submissions_classified.zst\"\n",
    "\n",
    "    # Load topic distribution from each submission classified\n",
    "    for line, file_bytes_processed in read_lines_zst(s_class):\n",
    "\n",
    "            # Convert the line to a json object\n",
    "            obj = json.loads(line)\n",
    "    \n",
    "            # Get link_id\n",
    "            link_id = obj['id']\n",
    "\n",
    "            # Find topic with highest probability\n",
    "            topic_dist = ast.literal_eval(obj['topic_dist'])\n",
    "            topic = find_max_tuple(topic_dist)[0]\n",
    "\n",
    "            # Add to dictionary\n",
    "            submissions_classified[sub][link_id] = {'topic': topic}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load submissions sentiment and get average sentiment\n",
    "submissions_sentiment = {s: {} for s in subreddits if s != 'politics'}\n",
    "\n",
    "for sub in subreddits[:-1]:\n",
    "    \n",
    "    s_sent = f\"analysis/sentiment/{sub}_submissions_sentiment.zst\"\n",
    "\n",
    "    # Load topic distribution from each submission classified\n",
    "    for line, file_bytes_processed in read_lines_zst(s_sent):\n",
    "\n",
    "            # Convert the line to a json object\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            # Get link_id\n",
    "            link_id = obj['link_id'].split('_')[-1]\n",
    "\n",
    "            # Get emotions, polarity, and subjectivity\n",
    "            emotions = obj['emotions']\n",
    "            polarity = obj['polarity']\n",
    "            subjectivity = obj['subjectivity']\n",
    "\n",
    "            # Add to dictionary\n",
    "            submissions_sentiment[sub][link_id] = {'emotions': emotions,\n",
    "                                                    'polarity': polarity,\n",
    "                                                    'subjectivity': subjectivity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all submissions_classified in each subreddit, and calcuate average sentiment and emotions for each topic\n",
    "submissions_classified_sentiment = {s: {} for s in subreddits if s != 'politics'}\n",
    "count = 0\n",
    "for sub in subreddits[:-1]:\n",
    "    count += 1\n",
    "    # Loop through submissions classified\n",
    "    for link_id, obj in submissions_classified[sub].items():\n",
    "\n",
    "        count += 1\n",
    "        if link_id not in submissions_sentiment[sub]:\n",
    "            continue\n",
    "\n",
    "        # Get topic\n",
    "        topic = obj['topic']\n",
    "\n",
    "        # Get sentiment and emotions from submissions sentiment\n",
    "        sentiment = submissions_sentiment[sub][link_id]\n",
    "        emotions = sentiment['emotions']\n",
    "        polarity = sentiment['polarity']\n",
    "        subjectivity = sentiment['subjectivity']\n",
    "\n",
    "        # Add to dictionary\n",
    "        if topic not in submissions_classified_sentiment[sub]:\n",
    "            submissions_classified_sentiment[sub][topic] = {'emotions': emotions,\n",
    "                                                            'polarity': polarity,\n",
    "                                                            'subjectivity': subjectivity,\n",
    "                                                            'count': 1}\n",
    "        else:\n",
    "            submissions_classified_sentiment[sub][topic]['emotions'] = {k: v + submissions_classified_sentiment[sub][topic]['emotions'][k] for k, v in emotions.items()}\n",
    "            submissions_classified_sentiment[sub][topic]['polarity'] += polarity\n",
    "            submissions_classified_sentiment[sub][topic]['subjectivity'] += subjectivity\n",
    "            submissions_classified_sentiment[sub][topic]['count'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each topic, plot the positive and negative emotions for each subreddit\n",
    "topics = {0: {}, 1: {}, 2: {}, 3: {}, 4: {}, 5: {}, 6: {}}\n",
    "for sub in subreddits[:-1]:\n",
    "\n",
    "    for t in range(7):\n",
    "        positive = submissions_classified_sentiment[sub][t]['emotions']['positive']\n",
    "        negative = submissions_classified_sentiment[sub][t]['emotions']['negative']\n",
    "        count = submissions_classified_sentiment[sub][t]['count']\n",
    "        topics[t][sub] = {'positive': positive/count, 'negative': negative/count}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping = {0: 'Judicial System', 1: 'Political Figures & Investigations', 2: 'International Affairs', 3: 'State Government', 4: 'Federal Government', 5: 'Social Issues', 6: 'Other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove from the keys the subreddits that are not needed (politics)\n",
    "topics_renamed = {k: {k2: v2 for k2, v2 in v.items() if k2 not in ['politics']} for k, v in topics.items()}\n",
    "\n",
    "# Rename they keys\n",
    "rename_dict = {'Conservative': 'Right-Leaning', 'Republican': 'Right-Leaning',\n",
    "               'democrats': 'Left-Leaning', 'progressive': 'Left-Leaning',\n",
    "               'NeutralPolitics': 'Neutral', 'PoliticalDiscussion': 'Neutral'}\n",
    "topics_renamed = {k: {rename_dict[k2]: v2 for k2, v2 in v.items()} for k, v in topics_renamed.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Government\n",
      "Social Issues\n"
     ]
    }
   ],
   "source": [
    "# Plot each topic as a bar chart\n",
    "for t in range(6):\n",
    "\n",
    "    values = topics_renamed[t]\n",
    "    df = pd.DataFrame(values).T\n",
    "    normalization_factor = df[\"positive\"] + df[\"negative\"]\n",
    "    df[\"overall\"] = (df[\"positive\"] - df[\"negative\"]) / normalization_factor\n",
    "    \n",
    "    # Plot the bar chart using seaborn\n",
    "    plt.figure(figsize=(12,8))\n",
    "\n",
    "    # Set the colors\n",
    "    colors = [\"#2ca4c4\" if val >= 0 else \"#e8f6b1\" for val in df[\"overall\"]]\n",
    "\n",
    "    # Plot positive and negative emotions as bar chart horizontally using seaborn\n",
    "    sns.barplot(y=df.index, x=df[\"overall\"], palette=colors)\n",
    "\n",
    "    # Set the title and axis labels\n",
    "    title = f\"{topic_mapping[t]}\"\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Polical Leaning\")\n",
    "    plt.xlabel(\"Polarity\")\n",
    "\n",
    "    # Make font size larger and plot smaller\n",
    "    plt.rc('font', size=20)\n",
    "    plt.rc('axes', titlesize=20)\n",
    "\n",
    "    # Find max absolute value in 'overall' column\n",
    "    max_abs = max(abs(df['overall']))\n",
    "    x_lim = 1.05 * max_abs\n",
    "\n",
    "    # Center the x-axis\n",
    "    plt.xlim(-x_lim, x_lim)\n",
    "\n",
    "    # Add line on 0\n",
    "    plt.axvline(x=0, color='gray')\n",
    "\n",
    "    # Save the image\n",
    "    plt.tight_layout(pad=1)\n",
    "    plt.savefig(f\"analysis/sentiment/plots/topic_{t}_positive_negative_emotions.png\")\n",
    "    #plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judicial System\n",
      "Right-Leaning   -0.002790\n",
      "Left-Leaning     0.026752\n",
      "Neutral          0.023971\n",
      "Name: overall, dtype: float64\n",
      "Political Figures & Investigations\n",
      "Right-Leaning    0.005511\n",
      "Left-Leaning     0.039028\n",
      "Neutral         -0.001507\n",
      "Name: overall, dtype: float64\n",
      "International Affairs\n",
      "Right-Leaning    0.027691\n",
      "Left-Leaning     0.012554\n",
      "Neutral          0.134846\n",
      "Name: overall, dtype: float64\n",
      "State Government\n",
      "Right-Leaning    0.028444\n",
      "Left-Leaning    -0.097354\n",
      "Neutral          0.003329\n",
      "Name: overall, dtype: float64\n",
      "Federal Government\n",
      "Right-Leaning    0.009953\n",
      "Left-Leaning     0.025542\n",
      "Neutral          0.008952\n",
      "Name: overall, dtype: float64\n",
      "Social Issues\n",
      "Right-Leaning   -0.143581\n",
      "Left-Leaning     0.056836\n",
      "Neutral         -0.005967\n",
      "Name: overall, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for t in range(6):\n",
    "\n",
    "    values = topics_renamed[t]\n",
    "    df = pd.DataFrame(values).T\n",
    "    normalization_factor = df[\"positive\"] + df[\"negative\"]\n",
    "    df[\"overall\"] = (df[\"positive\"] - df[\"negative\"]) / normalization_factor\n",
    "\n",
    "    print(topic_mapping[t])\n",
    "    print(df['overall'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
